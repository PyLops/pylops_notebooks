{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xaygeqc0YgF7"
      },
      "source": [
        "# Pylops - CUDA basic linear operators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "owGwScKKYgGA"
      },
      "source": [
        "### Author: M.Ravasi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IUIuNUfYYgGC"
      },
      "source": [
        "In this notebook we will experiment with Pytorch to assess its usability as backend for CUDA enabled operators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hMwmxTTxZ4Ju",
        "outputId": "8e0446e7-76a7-413b-c0cb-2c27c468216a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "!pip install pylops"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pylops\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/5a/dc9d93cd0f9ba3ea9a77c30c92865f07523ebf2fc391dff19aeca2f2b848/pylops-1.4.0-py3-none-any.whl (141kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pylops) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from pylops) (1.16.4)\n",
            "Installing collected packages: pylops\n",
            "Successfully installed pylops-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "86gLYP4HYgGI",
        "outputId": "67bd19c4-d0c8-4625-e636-c7144359e70c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "%pylab inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "\n",
        "import pylops\n",
        "from pylops.utils import dottest\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HKvxZ4rIY6dy",
        "outputId": "1a226c8e-3766-4c6a-f429-d9939aa5f4dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda installed! Running on GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "761LHiKWbCb3"
      },
      "source": [
        "# Diagonal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PjIkowKzbCby",
        "outputId": "25aa3b7a-71d7-409a-871f-d78227fed98a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nx = 100000\n",
        "x = np.ones(nx)\n",
        "Dop = pylops.Diagonal(np.arange(nx))\n",
        "dottest(Dop, nx, nx, verb=True)\n",
        "\n",
        "y  = Dop*x\n",
        "y1 = Dop.H*x"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dot test passed, v^T(Opu)=-18204277.587282 - u^T(Op^Tv)=-18204277.587282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rHFfMjiZuzWL",
        "colab": {}
      },
      "source": [
        "from pylops import LinearOperator\n",
        "\n",
        "class Diagonal_cuda(LinearOperator):\n",
        "    def __init__(self, diag, dtype='float64'):\n",
        "        self.diag = diag\n",
        "        self.dtype = np.dtype(dtype)\n",
        "        self.explicit = False\n",
        "\n",
        "    def _matvec(self, x):\n",
        "        y = self.diag*x\n",
        "        return y\n",
        "\n",
        "    def _rmatvec(self, x):\n",
        "        y = self.diag*x\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8mESLrHcvFwM",
        "outputId": "d2e61e0b-f18d-45cb-d2c5-db73a5762263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x_cuda = torch.from_numpy(np.ones(nx, dtype=np.float32)).to(device)\n",
        "diag_cuda = torch.from_numpy(np.arange(nx, dtype=np.float32)).to(device)\n",
        "Dop_cuda = Diagonal_cuda(diag_cuda)\n",
        "y_cuda = Dop_cuda._matvec(x_cuda)\n",
        "\n",
        "print('x  = ',x_cuda)\n",
        "print('D*x  = ',y_cuda)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x  =  tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')\n",
            "D*x  =  tensor([0.0000e+00, 1.0000e+00, 2.0000e+00,  ..., 9.9997e+04, 9.9998e+04,\n",
            "        9.9999e+04], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VjkC40YkyzwW",
        "outputId": "f50467fa-d697-42f0-e4a9-492ae925241c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "% timeit -n 10 Dop._matvec(x)\n",
        "% timeit -n 10 Dop_cuda._matvec(x_cuda)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 304 µs per loop\n",
            "The slowest run took 4.43 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10 loops, best of 3: 9.96 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9UsaZGZhccU",
        "colab_type": "text"
      },
      "source": [
        "# 1D Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7K9pSgihQNP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "089a8fda-cb75-404d-ef6f-c9c398f4e765"
      },
      "source": [
        "N = 11\n",
        "Nh = 3\n",
        "x = np.zeros(N)\n",
        "x[N//2] = 1\n",
        "\n",
        "h = np.arange(Nh)+1\n",
        "y = np.convolve(x, h, mode='same')\n",
        "print(y)\n",
        "print(y.shape)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 1. 2. 3. 0. 0. 0. 0.]\n",
            "(11,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hqf1yHfhHqU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8fa1ace3-bd55-40c0-856a-0bd5290b1e5d"
      },
      "source": [
        "xt = torch.zeros(N)\n",
        "xt[N//2] = 1\n",
        "\n",
        "ht = torch.torch.arange(0, Nh, dtype=torch.float) + 1.\n",
        "yt = torch.torch.conv_transpose1d(xt.reshape(1, 1, N), ht.reshape(1, 1, 3), padding=Nh//2)\n",
        "print(yt)\n",
        "print(yt.shape)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0., 0., 0., 0., 1., 2., 3., 0., 0., 0., 0.]]])\n",
            "torch.Size([1, 1, 11])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y7V0DRVkojI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c5742571-24f0-4c49-f7b3-8be2739b3f52"
      },
      "source": [
        "y = np.correlate(x, h, mode='same')\n",
        "print(y)\n",
        "\n",
        "yt = torch.torch.conv1d(xt.reshape(1, 1, N), ht.reshape(1, 1, 3), padding=Nh//2)\n",
        "print(yt)\n",
        "print(yt.shape)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 3. 2. 1. 0. 0. 0. 0.]\n",
            "tensor([[[0., 0., 0., 0., 3., 2., 1., 0., 0., 0., 0.]]])\n",
            "torch.Size([1, 1, 11])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxgUNx98haUX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgdPeJb0iCy1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "cf8284d3-a4cb-4091-85d7-a6db7a59cbc0"
      },
      "source": [
        "xt = torch.zeros((1000, N))\n",
        "xt[:, N//2] = 1\n",
        "ht = torch.torch.arange(0, Nh, dtype=torch.float) + 1.\n",
        "\n",
        "xc = xt.to(device)\n",
        "hc = ht.to(device)\n",
        "\n",
        "yt = torch.torch.conv1d(xt.reshape(1000, 1, N), ht.reshape(1, 1, 3), padding=Nh//2)\n",
        "print(yt.shape)\n",
        "yc = torch.torch.conv1d(xc.reshape(1000, 1, N), hc.reshape(1, 1, 3), padding=Nh//2)\n",
        "print(yc.shape)\n",
        "\n",
        "% timeit torch.torch.conv1d(xt.reshape(1000, 1, N), ht.reshape(1, 1, 3), padding=Nh//2)\n",
        "% timeit torch.torch.conv1d(xc.reshape(1000, 1, N), hc.reshape(1, 1, 3), padding=Nh//2)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 1, 11])\n",
            "torch.Size([1000, 1, 11])\n",
            "1000 loops, best of 3: 434 µs per loop\n",
            "The slowest run took 15.01 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000 loops, best of 3: 40.6 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}