{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xaygeqc0YgF7"
      },
      "source": [
        "# Pylops - CUDA basic linear operators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "owGwScKKYgGA"
      },
      "source": [
        "### Author: M.Ravasi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IUIuNUfYYgGC"
      },
      "source": [
        "In this notebook we will experiment with Pytorch to assess its usability as backend for CUDA enabled operators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hMwmxTTxZ4Ju",
        "outputId": "342c58b6-2fc0-438c-e813-ac91c7e9b6ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "!pip install pylops\n",
        "!pip install git+https://git@github.com/equinor/pylops-gpu.git@master"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pylops in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pylops) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from pylops) (1.16.4)\n",
            "Collecting git+https://git@github.com/equinor/pylops-gpu.git@master\n",
            "  Cloning https://git@github.com/equinor/pylops-gpu.git (to revision master) to /tmp/pip-req-build-isos42nz\n",
            "  Running command git clone -q https://git@github.com/equinor/pylops-gpu.git /tmp/pip-req-build-isos42nz\n",
            "Requirement already satisfied (use --upgrade to upgrade): pylops-gpu==0.0.0 from git+https://git@github.com/equinor/pylops-gpu.git@master in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from pylops-gpu==0.0.0) (1.16.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pylops-gpu==0.0.0) (1.1.0)\n",
            "Requirement already satisfied: pytorch_complex_tensor in /usr/local/lib/python3.6/dist-packages (from pylops-gpu==0.0.0) (0.0.134)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_complex_tensor->pylops-gpu==0.0.0) (0.3.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->pytorch_complex_tensor->pylops-gpu==0.0.0) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->pytorch_complex_tensor->pylops-gpu==0.0.0) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.2.1->pytorch_complex_tensor->pylops-gpu==0.0.0) (0.46)\n",
            "Building wheels for collected packages: pylops-gpu\n",
            "  Building wheel for pylops-gpu (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t8lxdp1j/wheels/c7/f0/0b/513e9be2dad0cbe2a900c0414a94bcae8778093383364aab9a\n",
            "Successfully built pylops-gpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "86gLYP4HYgGI",
        "outputId": "7dc1dbc0-b4a8-4e9b-c4aa-fb75faecc9d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "%pylab inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pylops\n",
        "from pylops import Diagonal\n",
        "from pylops.utils import dottest\n",
        "from pylops_gpu.utils.backend import device\n",
        "from pylops_gpu.utils import dottest as gdottest\n",
        "from pylops_gpu import Diagonal as gDiagonal"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5psZx5uvNM77",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc381fef-5f7d-465c-bf86-ff8fb06a640d"
      },
      "source": [
        "dev = device()\n",
        "print('PyLops-gpu working on %s...' % dev)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyLops-gpu working on cuda...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tW1zPopNUUk",
        "colab_type": "text"
      },
      "source": [
        "## Diagonal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXpLuro4Nalr",
        "colab_type": "text"
      },
      "source": [
        "Example with model and data already on GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS0QPHLwFutW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2ece0c29-96a8-4767-a189-1ff610e062c8"
      },
      "source": [
        "n = int(1e6)\n",
        "xg = torch.ones(n, dtype=torch.float32).to(dev)\n",
        "dg = (torch.arange(0, n, dtype=torch.float32) + 1.).to(dev)\n",
        "\n",
        "x = xg.cpu().numpy()\n",
        "d = dg.cpu().numpy()\n",
        "\n",
        "Dop = Diagonal(d)\n",
        "Dop_gpu = gDiagonal(dg, device=dev)\n",
        "dottest(Dop, n, n, verb=True)\n",
        "gdottest(Dop_gpu, n, n, device=dev, verb=True)\n",
        "\n",
        "# y = Dx\n",
        "yg = Dop_gpu * xg\n",
        "print('y', yg)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dot test passed, v^T(Opu)=-70078240.739681 - u^T(Op^Tv)=-70078240.739680\n",
            "Dot test passed, v^T(Opu)=124843622400.000000 - u^T(Op^Tv)=124843622400.000000\n",
            "y tensor([1.0000e+00, 2.0000e+00, 3.0000e+00,  ..., 1.0000e+06, 1.0000e+06,\n",
            "        1.0000e+06], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XER4rcF2Ni23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "361a5254-d941-4ab1-815a-6a30cdfe3d7c"
      },
      "source": [
        "%timeit -n 10 Dop * x\n",
        "%timeit -n 10 Dop_gpu * xg"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 853 µs per loop\n",
            "10 loops, best of 3: 15.5 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msimlxTDNn8U",
        "colab_type": "text"
      },
      "source": [
        "Example with model and data transfered from and to gpu in forward and adjoint operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfytb17lNLZN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "1cd0cce9-cee1-4c73-dddd-82060ff139ef"
      },
      "source": [
        "n = int(1e6)\n",
        "xg = torch.ones(n, dtype=torch.float32).to(dev)\n",
        "dg = (torch.arange(0, n, dtype=torch.float32) + 1.).to(dev)\n",
        "\n",
        "xc = xg.cpu()\n",
        "x = xg.cpu().numpy()\n",
        "d = dg.cpu().numpy()\n",
        "\n",
        "Dop = Diagonal(d)\n",
        "Dop_gpu = gDiagonal(dg, device=dev, togpu=(True, True), tocpu=(True, True))\n",
        "gdottest(Dop_gpu, n, n, verb=True)\n",
        "\n",
        "# y = Dx\n",
        "y = Dop_gpu * x\n",
        "print('y', yg)\n",
        "\n",
        "# xinv = D^-1 y\n",
        "xinv = Dop / y\n",
        "xinvg = Dop_gpu / y\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(x)\n",
        "plt.plot(xinv)\n",
        "plt.plot(xinvg, '--r')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dot test passed, v^T(Opu)=125046120448.000000 - u^T(Op^Tv)=125046120448.000000\n",
            "y tensor([1.0000e+00, 2.0000e+00, 3.0000e+00,  ..., 1.0000e+06, 1.0000e+06,\n",
            "        1.0000e+06], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6bba3f0eb8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a48_e6xIVHhu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f4fb2e21-45c6-43a2-d30e-8909dc430dcb"
      },
      "source": [
        "Dop_gpu = gDiagonal(dg, device=dev, togpu=(True, True))\n",
        "\n",
        "%timeit -n 10 Dop * x\n",
        "%timeit -n 10 Dop_gpu * xc"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 711 µs per loop\n",
            "10 loops, best of 3: 943 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXJkOrNtHMGn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "377539cc-c40f-4802-9cd1-fcc155a45946"
      },
      "source": [
        "Dop_gpu = gDiagonal(dg, device=dev, togpu=(True, True), tocpu=(True, True))\n",
        "\n",
        "%timeit -n 10 Dop * x\n",
        "%timeit -n 10 Dop_gpu * xc"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 760 µs per loop\n",
            "10 loops, best of 3: 2.39 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mo-JeU7iPSc4",
        "colab_type": "text"
      },
      "source": [
        "Note here how we get hit by the cost of moving x and y back and forth between CPU and GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9UsaZGZhccU",
        "colab_type": "text"
      },
      "source": [
        "# 1D Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7K9pSgihQNP",
        "colab_type": "code",
        "outputId": "82ab80d9-1e0a-4b9e-d1f2-7389b6799d71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "N = 11\n",
        "Nh = 3\n",
        "x = np.zeros(N)\n",
        "x[N//2] = 1\n",
        "\n",
        "h = np.arange(Nh)+1\n",
        "y = np.convolve(x, h, mode='same')\n",
        "print(y)\n",
        "print(y.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 1. 2. 3. 0. 0. 0. 0.]\n",
            "(11,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hqf1yHfhHqU",
        "colab_type": "code",
        "outputId": "b8524257-c208-4db3-9d87-2a2ea61026ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "xt = torch.zeros(N)\n",
        "xt[N//2] = 1\n",
        "\n",
        "ht = torch.torch.arange(0, Nh, dtype=torch.float) + 1.\n",
        "yt = torch.torch.conv_transpose1d(xt.reshape(1, 1, N), ht.reshape(1, 1, 3), padding=Nh//2)\n",
        "print(yt)\n",
        "print(yt.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0., 0., 0., 0., 1., 2., 3., 0., 0., 0., 0.]]])\n",
            "torch.Size([1, 1, 11])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y7V0DRVkojI",
        "colab_type": "code",
        "outputId": "e1312607-7ce2-4ff4-adb7-915121e56d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y = np.correlate(x, h, mode='same')\n",
        "print(y)\n",
        "\n",
        "yt = torch.torch.conv1d(xt.reshape(1, 1, N), ht.reshape(1, 1, 3), padding=Nh//2)\n",
        "print(yt)\n",
        "print(yt.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 3. 2. 1. 0. 0. 0. 0.]\n",
            "tensor([[[0., 0., 0., 0., 3., 2., 1., 0., 0., 0., 0.]]])\n",
            "torch.Size([1, 1, 11])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgdPeJb0iCy1",
        "colab_type": "code",
        "outputId": "7364e176-d6d5-4cd0-a27a-fb509e83470c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "xt = torch.zeros((1000, N))\n",
        "xt[:, N//2] = 1\n",
        "ht = torch.torch.arange(0, Nh, dtype=torch.float) + 1.\n",
        "\n",
        "xc = xt.to(dev)\n",
        "hc = ht.to(dev)\n",
        "\n",
        "yt = torch.torch.conv1d(xt.reshape(1000, 1, N), ht.reshape(1, 1, 3), padding=Nh//2)\n",
        "print(yt.shape)\n",
        "yc = torch.torch.conv1d(xc.reshape(1000, 1, N), hc.reshape(1, 1, 3), padding=Nh//2)\n",
        "print(yc.shape)\n",
        "\n",
        "% timeit torch.torch.conv1d(xt.reshape(1000, 1, N), ht.reshape(1, 1, 3), padding=Nh//2)\n",
        "% timeit torch.torch.conv1d(xc.reshape(1000, 1, N), hc.reshape(1, 1, 3), padding=Nh//2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 1, 11])\n",
            "torch.Size([1000, 1, 11])\n",
            "1000 loops, best of 3: 423 µs per loop\n",
            "The slowest run took 14.42 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000 loops, best of 3: 40.4 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wc7aNRXVnG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}