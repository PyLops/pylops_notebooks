{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pylops - torch operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: M.Ravasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will show how to use the `TorchOperator` to mix and match pylops and pytorch operators into an AD-friendy chain of operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import gradcheck\n",
    "from pylops.torchoperator import TorchOperator\n",
    "from pylops.basicoperators import *\n",
    "from pylops.signalprocessing import Convolve2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 10])\n",
      "Input:  tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "AD gradient:  tensor([-4.0933,  0.2311,  1.9883, -1.5357,  2.0949, -0.2220, -1.3530, -0.3468,\n",
      "         0.0438, -1.7114], dtype=torch.float64)\n",
      "Analytical gradient:  tensor([-4.0933,  0.2311,  1.9883, -1.5357,  2.0949, -0.2220, -1.3530, -0.3468,\n",
      "         0.0438, -1.7114], dtype=torch.float64, grad_fn=<MvBackward>)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "nx, ny = 10, 6\n",
    "x0 = torch.arange(nx, dtype=torch.double, requires_grad=True)\n",
    "\n",
    "# Forward\n",
    "A = np.random.normal(0., 1., (ny, nx))\n",
    "Aop = TorchOperator(MatrixMult(A))\n",
    "y = Aop.apply(torch.sin(x0))\n",
    "\n",
    "# AD\n",
    "v = torch.ones(ny, dtype=torch.double)\n",
    "y.backward(v, retain_graph=True)\n",
    "adgrad = x0.grad\n",
    "\n",
    "# Analytical\n",
    "At = torch.from_numpy(A)\n",
    "#J = (At * torch.cos(x0))\n",
    "J = (At * torch.cos(x0))\n",
    "print(J.shape)\n",
    "anagrad = torch.matmul(J.T, v)\n",
    "\n",
    "print('Input: ', x0)\n",
    "print('AD gradient: ', adgrad)\n",
    "print('Analytical gradient: ', anagrad)\n",
    "\n",
    "# Grad check\n",
    "input = (torch.arange(nx, dtype=torch.double, requires_grad=True),\n",
    "         Aop.matvec, Aop.rmatvec, Aop.device, 'cpu')\n",
    "test = gradcheck(Aop.Top, input, eps=1e-6, atol=1e-4)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi batch, we should get here to sum of gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AD gradient:  tensor([[ 1.8780, -2.3417,  0.5176],\n",
      "        [-1.8592,  2.8330, -0.3528],\n",
      "        [ 1.8032, -3.2675,  0.1810],\n",
      "        [-1.7111,  3.6367, -0.0055],\n",
      "        [ 1.5848, -3.9330, -0.1701]])\n",
      "Analytical gradient:  tensor([[ 1.8780, -2.3417,  0.5176],\n",
      "        [-1.8592,  2.8330, -0.3528],\n",
      "        [ 1.8032, -3.2675,  0.1810],\n",
      "        [-1.7111,  3.6367, -0.0055],\n",
      "        [ 1.5848, -3.9330, -0.1701]])\n"
     ]
    }
   ],
   "source": [
    "nbatch, nx, ny = 5, 3, 6\n",
    "x0 = torch.arange(nbatch * nx, dtype=torch.float).reshape(nbatch, nx)\n",
    "x0.requires_grad=True\n",
    "\n",
    "# Forward\n",
    "A = np.random.normal(0., 1., (ny, nx)).astype(np.float32)\n",
    "Aop = TorchOperator(MatrixMult(A), batch=True)\n",
    "y = Aop.apply(torch.sin(x0))\n",
    "\n",
    "# AD\n",
    "v = torch.ones((nbatch, ny), dtype=torch.float32)\n",
    "y.backward(v, retain_graph=True)\n",
    "adgrad = x0.grad\n",
    "print('AD gradient: ', adgrad)\n",
    "\n",
    "# Analytical\n",
    "x0.grad.data.zero_()\n",
    "At = torch.from_numpy(A)\n",
    "Lin = nn.Linear(nx, ny, bias=False)\n",
    "Lin.weight.data[:] = At.float()\n",
    "y1 = Lin(torch.sin(x0))\n",
    "y1.backward(v, retain_graph=True)\n",
    "anagrad = x0.grad\n",
    "\n",
    "print('Analytical gradient: ', anagrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AD gradient:  tensor([[ 0.0810,  0.2892, -0.0766],\n",
      "        [ 0.0245,  0.2966, -0.0587],\n",
      "        [-0.0307,  0.2739, -0.0329],\n",
      "        [-0.0802,  0.2228, -0.0011],\n",
      "        [-0.1201,  0.1474,  0.0341]])\n",
      "Analytical gradient:  tensor([[ 0.0810,  0.2892, -0.0766],\n",
      "        [ 0.0245,  0.2966, -0.0587],\n",
      "        [-0.0307,  0.2739, -0.0329],\n",
      "        [-0.0802,  0.2228, -0.0011],\n",
      "        [-0.1201,  0.1474,  0.0341]])\n"
     ]
    }
   ],
   "source": [
    "nbatch, nx, ny = 5, 3, 6\n",
    "x0 = torch.arange(nbatch*nx, dtype=torch.float).reshape(nbatch, nx).requires_grad_()\n",
    "\n",
    "# Forward\n",
    "A = np.random.normal(0., 1., (ny, nx)).astype(np.float32)\n",
    "Aop = TorchOperator(MatrixMult(A), batch=True)\n",
    "y = Aop.apply(torch.sin(x0))\n",
    "l = torch.mean(y**2)\n",
    "l.backward()\n",
    "adgrad = x0.grad\n",
    "print('AD gradient: ', adgrad)\n",
    "\n",
    "# Analytical\n",
    "x1 = torch.arange(nbatch*nx, dtype=torch.float).reshape(nbatch, nx).requires_grad_()\n",
    "At = torch.from_numpy(A)\n",
    "Lin = nn.Linear(nx, ny, bias=False)\n",
    "Lin.weight.data[:] = At.float()\n",
    "y1 = Lin(torch.sin(x1))\n",
    "l1 = torch.mean(y1**2)\n",
    "l1.backward()\n",
    "anagrad = x1.grad\n",
    "\n",
    "print('Analytical gradient: ', anagrad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixing NN and Physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, input_channels // 2, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(input_channels // 2, input_channels // 4, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(input_channels // 4, input_channels // 8, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(input_channels // 8, input_channels // 32, kernel_size=3, padding=1)\n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(4, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (activation): LeakyReLU(negative_slope=0.2)\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_cpu = Network(32)\n",
    "net_gpu = Network(32)\n",
    "net_gpu.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.4 ms ± 83.8 µs per loop (mean ± std. dev. of 2 runs, 2 loops each)\n",
      "43.8 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# CPU\n",
    "h = np.ones((4, 4))\n",
    "Pop = Convolve2D(dims=(128, 128), h=h)\n",
    "Pop_torch_cpu = TorchOperator(Pop, device='cpu')\n",
    "\n",
    "# forward\n",
    "%timeit -n2 -r2 Pop_torch_cpu.apply(net_cpu(torch.ones((1, 32, 128, 128))).view(-1))\n",
    "\n",
    "# backward\n",
    "y = Pop_torch_cpu.apply(net_cpu(torch.ones((1, 32, 128, 128))).view(-1))\n",
    "loss = y.sum()\n",
    "%timeit -n1 -r1 loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.91 ms ± 505 µs per loop (mean ± std. dev. of 2 runs, 2 loops each)\n",
      "29.1 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "h = np.ones((4, 4))\n",
    "Pop = Convolve2D(dims=(128, 128), h=h)\n",
    "Pop_torch_gpu = TorchOperator(Pop, device=device)\n",
    "Pop_torch_gpu.apply(net_gpu(torch.ones((1, 32, 128, 128)).to(device)).view(-1)) # dry run\n",
    "\n",
    "%timeit -n2 -r2 Pop_torch_gpu.apply(net_gpu(torch.ones((1, 32, 128, 128)).to(device)).view(-1))\n",
    "\n",
    "# backward\n",
    "y = Pop_torch_gpu.apply(net_gpu(torch.ones((1, 32, 128, 128)).to(device)).view(-1))\n",
    "loss = y.sum()\n",
    "%timeit -n1 -r1 loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.45 ms ± 718 µs per loop (mean ± std. dev. of 2 runs, 2 loops each)\n",
      "23.5 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Mixed (currently not allowed!)\n",
    "h = np.ones((4, 4))\n",
    "Pop = Convolve2D(dims=(128, 128), h=h)\n",
    "Pop_torch_cpu = TorchOperator(Pop, device='cpu', devicetorch=device.type)\n",
    "\n",
    "# forward\n",
    "Pop_torch_cpu.apply(net_gpu(torch.ones((1, 32, 128, 128)).to(device)).view(-1)) # dry run\n",
    "%timeit -n2 -r2 Pop_torch_cpu.apply(net_gpu(torch.ones((1, 32, 128, 128)).to(device)).view(-1))\n",
    "\n",
    "# backward\n",
    "y = Pop_torch_cpu.apply(net_gpu(torch.ones((1, 32, 128, 128)).to(device)).view(-1))\n",
    "loss = y.sum()\n",
    "%timeit -n1 -r1 loss.backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
