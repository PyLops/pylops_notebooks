{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pylops - torch operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: M.Ravasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will show how to use the `TorchOperator` to mix and match pylops and pytorch operators into an AD-friendy chain of operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pylops.torchoperator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/ravasim/Documents/OpenSource/pylops_notebooks/developement/TorchOperator.ipynb Cell 4\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkw60931.kaust.edu.sa/home/ravasim/Documents/OpenSource/pylops_notebooks/developement/TorchOperator.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkw60931.kaust.edu.sa/home/ravasim/Documents/OpenSource/pylops_notebooks/developement/TorchOperator.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m \u001b[39mimport\u001b[39;00m gradcheck\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bkw60931.kaust.edu.sa/home/ravasim/Documents/OpenSource/pylops_notebooks/developement/TorchOperator.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpylops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtorchoperator\u001b[39;00m \u001b[39mimport\u001b[39;00m TorchOperator\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkw60931.kaust.edu.sa/home/ravasim/Documents/OpenSource/pylops_notebooks/developement/TorchOperator.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpylops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbasicoperators\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkw60931.kaust.edu.sa/home/ravasim/Documents/OpenSource/pylops_notebooks/developement/TorchOperator.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpylops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msignalprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m Convolve2D\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pylops.torchoperator'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import gradcheck\n",
    "from pylops.torchoperator import TorchOperator\n",
    "from pylops.basicoperators import *\n",
    "from pylops.signalprocessing import Convolve2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx, ny = 10, 6\n",
    "x0 = torch.arange(nx, dtype=torch.double, requires_grad=True)\n",
    "\n",
    "# Forward\n",
    "A = np.random.normal(0., 1., (ny, nx))\n",
    "Aop = TorchOperator(MatrixMult(A))\n",
    "y = Aop.apply(torch.sin(x0))\n",
    "\n",
    "# AD\n",
    "v = torch.ones(ny, dtype=torch.double)\n",
    "y.backward(v, retain_graph=True)\n",
    "adgrad = x0.grad\n",
    "\n",
    "# Analytical\n",
    "At = torch.from_numpy(A)\n",
    "#J = (At * torch.cos(x0))\n",
    "J = (At * torch.cos(x0))\n",
    "print(J.shape)\n",
    "anagrad = torch.matmul(J.T, v)\n",
    "\n",
    "print('Input: ', x0)\n",
    "print('AD gradient: ', adgrad)\n",
    "print('Analytical gradient: ', anagrad)\n",
    "\n",
    "# Grad check\n",
    "input = (torch.arange(nx, dtype=torch.double, requires_grad=True),\n",
    "         Aop.matvec, Aop.rmatvec, Aop.device, 'cpu')\n",
    "test = gradcheck(Aop.Top, input, eps=1e-6, atol=1e-4)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi batch, we should get here to sum of gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nbatch, nx, ny = 5, 3, 6\n",
    "x0 = torch.arange(nbatch * nx, dtype=torch.float).reshape(nbatch, nx)\n",
    "x0.requires_grad=True\n",
    "\n",
    "# Forward\n",
    "A = np.random.normal(0., 1., (ny, nx)).astype(np.float32)\n",
    "Aop = TorchOperator(MatrixMult(A), batch=True)\n",
    "y = Aop.apply(torch.sin(x0))\n",
    "\n",
    "# AD\n",
    "v = torch.ones((nbatch, ny), dtype=torch.float32)\n",
    "y.backward(v, retain_graph=True)\n",
    "adgrad = x0.grad\n",
    "print('AD gradient: ', adgrad)\n",
    "\n",
    "# Analytical\n",
    "x0.grad.data.zero_()\n",
    "At = torch.from_numpy(A)\n",
    "Lin = nn.Linear(nx, ny, bias=False)\n",
    "Lin.weight.data[:] = At.float()\n",
    "y1 = Lin(torch.sin(x0))\n",
    "y1.backward(v, retain_graph=True)\n",
    "anagrad = x0.grad\n",
    "\n",
    "print('Analytical gradient: ', anagrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbatch, nx, ny = 5, 3, 6\n",
    "x0 = torch.arange(nbatch*nx, dtype=torch.float).reshape(nbatch, nx).requires_grad_()\n",
    "\n",
    "# Forward\n",
    "A = np.random.normal(0., 1., (ny, nx)).astype(np.float32)\n",
    "Aop = TorchOperator(MatrixMult(A), batch=True)\n",
    "y = Aop.apply(torch.sin(x0))\n",
    "l = torch.mean(y**2)\n",
    "l.backward()\n",
    "adgrad = x0.grad\n",
    "print('AD gradient: ', adgrad)\n",
    "\n",
    "# Analytical\n",
    "x1 = torch.arange(nbatch*nx, dtype=torch.float).reshape(nbatch, nx).requires_grad_()\n",
    "At = torch.from_numpy(A)\n",
    "Lin = nn.Linear(nx, ny, bias=False)\n",
    "Lin.weight.data[:] = At.float()\n",
    "y1 = Lin(torch.sin(x1))\n",
    "l1 = torch.mean(y1**2)\n",
    "l1.backward()\n",
    "anagrad = x1.grad\n",
    "\n",
    "print('Analytical gradient: ', anagrad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixing NN and Physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, input_channels // 2, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(input_channels // 2, input_channels // 4, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(input_channels // 4, input_channels // 8, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(input_channels // 8, input_channels // 32, kernel_size=3, padding=1)\n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_cpu = Network(32)\n",
    "net_gpu = Network(32)\n",
    "net_gpu.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU\n",
    "h = np.ones((4, 4))\n",
    "Pop = Convolve2D(dims=(128, 128), h=h)\n",
    "Pop_torch_cpu = TorchOperator(Pop, device='cpu')\n",
    "\n",
    "# forward\n",
    "%timeit -n2 -r2 Pop_torch_cpu.apply(net_cpu(torch.ones((1, 32, 128, 128))).view(-1))\n",
    "\n",
    "# backward\n",
    "y = Pop_torch_cpu.apply(net_cpu(torch.ones((1, 32, 128, 128))).view(-1))\n",
    "loss = y.sum()\n",
    "%timeit -n1 -r1 loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU\n",
    "h = np.ones((4, 4))\n",
    "Pop = Convolve2D(dims=(128, 128), h=h)\n",
    "Pop_torch_gpu = TorchOperator(Pop, device=device)\n",
    "Pop_torch_gpu.apply(net_gpu(torch.ones((1, 32, 128, 128)).to(device)).view(-1)) # dry run\n",
    "\n",
    "%timeit -n2 -r2 Pop_torch_gpu.apply(net_gpu(torch.ones((1, 32, 128, 128)).to(device)).view(-1))\n",
    "\n",
    "# backward\n",
    "y = Pop_torch_gpu.apply(net_gpu(torch.ones((1, 32, 128, 128)).to(device)).view(-1))\n",
    "loss = y.sum()\n",
    "%timeit -n1 -r1 loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed (currently not allowed!)\n",
    "h = np.ones((4, 4))\n",
    "Pop = Convolve2D(dims=(128, 128), h=h)\n",
    "Pop_torch_cpu = TorchOperator(Pop, device='cpu', devicetorch=device.type)\n",
    "\n",
    "# forward\n",
    "Pop_torch_cpu.apply(net_gpu(torch.ones((1, 32, 128, 128)).to(device)).view(-1)) # dry run\n",
    "%timeit -n2 -r2 Pop_torch_cpu.apply(net_gpu(torch.ones((1, 32, 128, 128)).to(device)).view(-1))\n",
    "\n",
    "# backward\n",
    "y = Pop_torch_cpu.apply(net_gpu(torch.ones((1, 32, 128, 128)).to(device)).view(-1))\n",
    "loss = y.sum()\n",
    "%timeit -n1 -r1 loss.backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('pylops_gpu_3090_torch1_10_1': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "17f9aaec73ef57837ac82ec8cd1e0a65387e9eb595a33317b829a9862250a9db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
